**Запуск AirFlow**\
docker-compose up --build\
**Запуса тестов**
pytest -v tests/\
\
Самоанализ:\
1) + (5 баллов) Реализуйте dag, который генерирует данные для обучения модели (генерируйте данные, можете использовать как генератор синтетики из первой дз, так и что-то из датасетов sklearn), вам важно проэмулировать ситуации постоянно поступающих данных

2) + (10 баллов) Реализуйте dag, который обучает модель еженедельно, используя данные за текущий день. В вашем пайплайне должно быть как минимум 4 стадии, но дайте волю своей фантазии=)

3) + Реализуйте dag, который использует модель ежедневно (5 баллов)

3а) Вот с этим проблемы, вроде все правильно написал, но почему-то не работает, возможно это какие-то приколы винды, буду благодарен за помощь:) Реализуйте сенсоры на то, что данные готовы для дагов тренировки и обучения (3 доп балла)

4) + вы можете выбрать 2 пути для выполнения ДЗ. 
-- все даги реализованы только с помощью DockerOperator (10 баллов) (пример https://github.com/made-ml-in-prod-2021/airflow-examples/blob/main/dags/11_docker.py).
По технике, вы можете использовать такую же структуру как в примере, пакую в разные докеры скрипты, можете использовать общий докер с вашим пакетом, но с разными точками входа для разных тасок. 

5) + Протестируйте ваши даги (5 баллов) https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html 
6) - В docker compose так же настройте поднятие mlflow и запишите туда параметры обучения, метрики и артефакт(модель) (5 доп баллов)
7) - вместо пути в airflow variables  используйте апи Mlflow Model Registry (5 доп баллов)
Даг для инференса подхватывает последнюю продакшен модель. 
8) + (p.s. я там убрал свою почту и пароль) Настройте alert в случае падения дага (3 доп. балла)
https://www.astronomer.io/guides/error-notifications-in-airflow
9) + традиционно, самооценка (1 балл)
    
Итого: 39